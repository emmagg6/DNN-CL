{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import neptune\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
    "\n",
    "import trainer\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "    # train_loader, val_loader, test_loader = utils.prepare_movingmnist(\n",
    "    #     hparams['batch_size'], data_dir=data_dir)\n",
    "train_loader, val_loader, test_loader = utils.prepare_mm(128, data_dir='ConvLSTM/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, train_criterion, test_criterion, i_lr=0.001):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Set hyperparameters\n",
    "        self.h_act = torch.nn.Tanh()\n",
    "        self.in_dim = in_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        # Manual RNN\n",
    "        self.W_xh = torch.nn.Linear(self.in_dim, self.hidden_dim, bias=False)\n",
    "        self.Wb_hh = torch.nn.Linear(self.hidden_dim, self.hidden_dim, bias=True)\n",
    "        self.Vc_hh = torch.nn.Linear(self.hidden_dim, self.hidden_dim, bias=True)\n",
    "        self.Wb_hy = torch.nn.Linear(self.hidden_dim, self.out_dim, bias=True)\n",
    "\n",
    "        # For managing training process\n",
    "        self.device = None\n",
    "        self.training_criterion = train_criterion\n",
    "        self.test_criterion = test_criterion\n",
    "        self.hidden_criterion = torch.nn.MSELoss()\n",
    "        self.i_lr = i_lr # to set local target\n",
    "\n",
    "    def F_hh(self, x_t, h_tm1):\n",
    "        return self.h_act(self.W_xh(x_t) + self.Wb_hh(h_tm1))\n",
    "    def G_hh(self, x_t, h_t):\n",
    "        return self.h_act(self.W_xh(x_t) + self.Vc_hh(h_t))\n",
    "        \n",
    "    def set_device(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    def get_device(self):\n",
    "        return self.device\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.transpose(x, 0, 1)/1.  # seq_len first\n",
    "        in_len, batch_sz, h, w = x.shape\n",
    "        out_len = in_len\n",
    "        \n",
    "\n",
    "        h_ = torch.zeros(batch_sz, self.hidden_dim, device=self.get_device())\n",
    "\n",
    "        for in_idx in range(in_len-1):\n",
    "            x_ = x[in_idx].view(batch_sz, -1)  # [batch_sz, self.in_dim]\n",
    "            h_ = self.h_act(self.W_xh(x_) + self.Wb_hh(h_))\n",
    "\n",
    "        Ys = []\n",
    "        y_ = x[in_len-1].view(batch_sz, -1)\n",
    "\n",
    "        for _ in range(out_len):\n",
    "            h_ = self.h_act(self.W_xh(y_) + self.Wb_hh(h_))\n",
    "            y_ = self.Wb_hy(h_)\n",
    "            Ys.append(y_.view(batch_sz, h, w))\n",
    "            y_ = y_.sigmoid()\n",
    "\n",
    "        # [batch_sz, out_len, 64, 64] values [0., 1.]\n",
    "        return torch.transpose(torch.stack(Ys, 0), 0, 1)\n",
    "\n",
    "    \n",
    "# Train epoch\n",
    "    def train_epoch(self, train_loader, optimizers, logger, epoch, verbose=True):  # might be None\n",
    "        G_losses_list = []\n",
    "        F_losses_list = []\n",
    "        Y_losses_list = []\n",
    "        opt_g, opt_f, opt_y = optimizers\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            batch = [batch[2].squeeze(), batch[1].squeeze()]\n",
    "            x = torch.transpose(torch.cat(batch, 1), 0, 1)/1.\n",
    "            # print(x.max())\n",
    "            x = x.to(self.get_device())\n",
    "            total_len, batch_sz, h, w = x.shape\n",
    "            h_ = torch.zeros(batch_sz, self.hidden_dim,\n",
    "                             device=self.get_device())\n",
    "            p_out = []\n",
    "            h_preactivations = []\n",
    "            \n",
    "            x_preactivations = []\n",
    "            Y_losses = []\n",
    "            \n",
    "            h_local_tar = []\n",
    "            h_acts = []\n",
    "            \n",
    "            # Forward pass\n",
    "            for idx in range(total_len - 1):\n",
    "                # idx = 0 -> 18\n",
    "                x_i = x[idx].view(batch_sz, h*w) # [batch_sz, self.in_dim]\n",
    "                x_ip1 = x[idx+1].view(batch_sz, h*w)\n",
    "                \n",
    "                # Forward activations \n",
    "                h_preactivation = self.Wb_hh(h_.detach())\n",
    "                x_preactivation = self.W_xh(x_i.detach())\n",
    "#                 x_preactivations.append(x_preactivation)\n",
    "                \n",
    "                h_activation = self.h_act(h_preactivation + x_preactivation)\n",
    "                h_acts.append(h_activation)\n",
    "                \n",
    "                # step y loss and local target\n",
    "                h_copy_w_grad = h_activation.detach()\n",
    "                h_copy_w_grad.requires_grad = True\n",
    "                \n",
    "                y_pred = self.Wb_hy(h_copy_w_grad)\n",
    "                step_loss = self.training_criterion(y_pred, x_ip1)\n",
    "                step_loss.backward(retain_graph=True) # reuse later\n",
    "                Y_losses.append(step_loss)\n",
    "                \n",
    "                local_target = (h_copy_w_grad - self.i_lr * h_copy_w_grad.grad).detach()\n",
    "                h_copy_w_grad.grad.zero_() # for later update\n",
    "                h_copy_w_grad.requries_grad=False \n",
    "                self.Wb_hy.weight.grad.zero_() # for later update\n",
    "                self.Wb_hy.bias.grad.zero_() # for later update\n",
    "                h_local_tar.append(local_target)\n",
    "                \n",
    "                # Recursive step\n",
    "                h_ = h_activation.detach()\n",
    "            \n",
    "            # Backward pass\n",
    "            G_losses = []\n",
    "            F_losses = []\n",
    "            \n",
    "            for idx in range(total_len-3, -1, -1):\n",
    "                # idx = 17 -> 0\n",
    "                arg1 = x[idx+1].view([batch_sz, h*w])\n",
    "#                 print(arg1.shape)\n",
    "                arg2 = h_acts[idx+1].detach()\n",
    "#                 print(arg2.shape)\n",
    "                G_h = self.G_hh(arg1, arg2)\n",
    "                G_h_hat = self.G_hh(x[idx+1].view(batch_sz, h*w), h_local_tar[idx+1].detach())\n",
    "                \n",
    "                total = (total_len - 1) - idx\n",
    "                beta = 1./total # weight for current loss\n",
    "                alpha = 1 - beta\n",
    "                h_local_tar[idx] = (beta * h_local_tar[idx] + alpha * (h_acts[idx].detach() - G_h + G_h_hat)).detach()\n",
    "                g_loss = self.hidden_criterion(G_h, h_acts[idx].detach())\n",
    "                G_losses.append(g_loss)\n",
    "                \n",
    "                f_loss = self.hidden_criterion(h_acts[idx+1], h_local_tar[idx+1])\n",
    "                F_losses.append(f_loss)\n",
    "            \n",
    "            G_loss_batch = torch.stack(G_losses).mean()\n",
    "            F_loss_batch = torch.stack(F_losses).mean()\n",
    "            Y_loss_batch = torch.stack(Y_losses).mean()\n",
    "            \n",
    "            opt_g.zero_grad()\n",
    "            opt_f.zero_grad()\n",
    "            opt_y.zero_grad()\n",
    "            G_loss_batch.backward()\n",
    "            F_loss_batch.backward()\n",
    "            Y_loss_batch.backward()\n",
    "            opt_g.step()\n",
    "            \n",
    "        \n",
    "            if logger:\n",
    "                epoch_float = epoch + (batch_idx+1)/len(train_loader)\n",
    "                logger.log_metric('train_g_loss', epoch_float, G_loss_batch)\n",
    "                logger.log_metric('train_f_loss', epoch_float, F_loss_batch)\n",
    "                logger.log_metric('train_y_loss', epoch_float, Y_loss_batch)\n",
    "            F_losses_list.append(F_loss_batch)\n",
    "            Y_losses_list.append(F_loss_batch)\n",
    "            G_losses_list.append(G_loss_batch) \n",
    "                 \n",
    "#         for batch_idx, batch in enumerate(train_loader):\n",
    "#             batch = [batch[2].squeeze(), batch[1].squeeze()]\n",
    "#             x = torch.transpose(torch.cat(batch, 1), 0, 1)/1.\n",
    "#             # print(x.max())\n",
    "#             x = x.to(self.get_device())\n",
    "#             total_len, batch_sz, h, w = x.shape\n",
    "#             h_ = torch.zeros(batch_sz, self.hidden_dim,\n",
    "#                              device=self.get_device())\n",
    "#             p_out = []\n",
    "#             h_preactivations = []\n",
    "            \n",
    "#             x_preactivations = []\n",
    "#             Y_losses = []\n",
    "            \n",
    "#             h_local_tar = []\n",
    "#             h_acts = []\n",
    "            \n",
    "#             # Forward pass\n",
    "#             for idx in range(total_len - 1):\n",
    "#                 # idx = 0 -> 18\n",
    "#                 x_i = x[idx].view(batch_sz, h*w) # [batch_sz, self.in_dim]\n",
    "#                 x_ip1 = x[idx+1].view(batch_sz, h*w)\n",
    "                \n",
    "#                 # Forward activations \n",
    "#                 h_preactivation = self.Wb_hh(h_.detach())\n",
    "#                 x_preactivation = self.W_xh(x_i.detach())\n",
    "# #                 x_preactivations.append(x_preactivation)\n",
    "                \n",
    "#                 h_activation = self.h_act(h_preactivation + x_preactivation)\n",
    "#                 h_acts.append(h_activation)\n",
    "                \n",
    "#                 # step y loss and local target\n",
    "#                 h_copy_w_grad = h_activation.detach()\n",
    "#                 h_copy_w_grad.requires_grad = True\n",
    "                \n",
    "#                 y_pred = self.Wb_hy(h_copy_w_grad)\n",
    "#                 step_loss = self.training_criterion(y_pred, x_ip1)\n",
    "#                 step_loss.backward(retain_graph=True) # reuse later\n",
    "#                 Y_losses.append(step_loss)\n",
    "                \n",
    "#                 local_target = (h_copy_w_grad - self.i_lr * h_copy_w_grad.grad).detach()\n",
    "#                 h_copy_w_grad.grad.zero_() # for later update\n",
    "#                 h_copy_w_grad.requries_grad=False \n",
    "#                 self.Wb_hy.weight.grad.zero_() # for later update\n",
    "#                 self.Wb_hy.bias.grad.zero_() # for later update\n",
    "#                 h_local_tar.append(local_target)\n",
    "                \n",
    "#                 # Recursive step\n",
    "#                 h_ = h_activation.detach()\n",
    "            \n",
    "#             # Backward pass\n",
    "#             G_losses = []\n",
    "#             F_losses = []\n",
    "# #             hidden_criterion\n",
    "#             for idx in range(total_len-3, -1, -1):\n",
    "#                 # idx = 17 -> 0\n",
    "#                 G_h = self.G_hh(x[idx+1].view(batch_sz, h*w), h_acts[idx+1].detach())\n",
    "#                 G_h_hat = self.G_hh(x[idx+1].view(batch_sz, h*w), h_local_tar[idx+1].detach())\n",
    "                \n",
    "#                 total = (total_len - 1) - idx\n",
    "#                 beta = 1./total # weight for current loss\n",
    "#                 alpha = 1 - beta\n",
    "#                 h_local_tar[idx] = (beta * h_local_tar[idx] + alpha * (h_acts[idx].detach() - G_h + G_h_hat)).detach()\n",
    "#                 g_loss = self.hidden_criterion(G_h, h_acts[idx].detach())\n",
    "#                 G_losses.append(g_loss)\n",
    "                \n",
    "#                 f_loss = self.hidden_criterion(h_acts[idx+1], h_local_tar[idx+1])\n",
    "#                 F_losses.append(f_loss)\n",
    "            \n",
    "#             G_loss_batch = torch.stack(G_losses).mean()\n",
    "#             F_loss_batch = torch.stack(F_losses).mean()\n",
    "#             Y_loss_batch = torch.stack(Y_losses).mean()\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "#             F_loss_batch.backward()\n",
    "#             Y_loss_batch.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "        \n",
    "#             if logger:\n",
    "#                 epoch_float = epoch + (batch_idx+1)/len(train_loader)\n",
    "#                 logger.log_metric('train_f_loss', epoch_float, F_loss_batch)\n",
    "#                 logger.log_metric('train_y_loss', epoch_float, Y_loss_batch)\n",
    "#             F_losses_list.append(F_loss_batch)\n",
    "#             Y_losses_list.append(F_loss_batch)\n",
    "                \n",
    "        return G_losses_list, F_losses_list, Y_losses_list\n",
    "\n",
    "    def validation(self, val_loader, logger, epoch, verbose=True):\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = torch.zeros(1, device=self.get_device())\n",
    "            log_image_batch_idx = torch.randint(0, len(val_loader), [1])\n",
    "            for batch_idx, batch in enumerate(val_loader):\n",
    "                # batch = [batch[1], batch[0]]\n",
    "                batch = [batch[2].squeeze(), batch[1].squeeze()]\n",
    "                x = torch.transpose(torch.cat(batch, 1), 0, 1)/1.\n",
    "                x = x.to(self.get_device())\n",
    "                total_len, batch_sz, h, w = x.shape\n",
    "                h_ = torch.zeros(batch_sz, self.hidden_dim,\n",
    "                                 device=self.get_device())\n",
    "                p_out = []\n",
    "\n",
    "                for idx in range(total_len-1):\n",
    "                    x_ = x[idx].view(batch_sz, h*w)  # [batch_sz, self.in_dim]\n",
    "                    h_ = self.h_act(self.Wb_xh(x_) + self.Wb_hh(h_))\n",
    "                    p_ = self.Wb_hy(h_).view(batch_sz, h, w)\n",
    "                    p_out.append(p_)\n",
    "\n",
    "                y_logits = torch.stack(p_out, 0)\n",
    "                gt = x[1:]\n",
    "                loss = self.training_criterion(torch.transpose(\n",
    "                    y_logits, 0, 1), torch.transpose(gt, 0, 1))  # [19, batch_sz, h, w]\n",
    "                total_loss += loss\n",
    "\n",
    "                # log images\n",
    "                if logger and (batch_idx == log_image_batch_idx):\n",
    "\n",
    "                    sample_seq_idx = torch.randint(0, batch_sz, [1])\n",
    "                    \n",
    "                    x_gt = batch[1][sample_seq_idx, :, :, :].squeeze().to(self.get_device()) # seq, h, w\n",
    "                    assert(x_gt.max() <= 1.)\n",
    "                    # print(x_gt.shape)\n",
    "\n",
    "                    x_in = batch[0][sample_seq_idx:sample_seq_idx+1, :, :, :].to(self.get_device()) # 1, seq, h, w\n",
    "                    \n",
    "                    x_pred = self.forward(x_in).squeeze().sigmoid_()\n",
    "                    assert(x_pred.max() <= 1.)\n",
    "                    # print(x_pred.shape)\n",
    "\n",
    "                    x_in_ = x_in.squeeze()/1.\n",
    "                    # print(x_in_.shape)\n",
    "                    assert(x_in_.max() <= 1.)\n",
    "                    \n",
    "\n",
    "                    utils.log_images_to_meptune(\n",
    "                        \"Predicted frames\", [x_in_, x_gt, x_pred], logger)\n",
    "\n",
    "            mean_loss = total_loss/len(val_loader)\n",
    "            if logger:\n",
    "                logger.log_metric('val_loss', epoch, mean_loss)\n",
    "        self.train()\n",
    "        if verbose:\n",
    "            print(f\"{epoch:d} \\t\\t {mean_loss.item():.04f} \\t\\t\")\n",
    "        return mean_loss\n",
    "\n",
    "    def test(self, test_loader, logger=None, verbose=True):\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            total_loss = torch.zeros(1, device=self.get_device())\n",
    "            for idx, batch in enumerate(test_loader):\n",
    "                batch = [batch[2].squeeze(), batch[1].squeeze()]\n",
    "                x, y = [item.to(self.get_device()) for item in batch]\n",
    "                # y = y/255.\n",
    "                y = y/1.\n",
    "                assert (y.max() <= 1.)\n",
    "                # [batch_sz, seq_len, h, w] in [0, 1]\n",
    "                pred_frames = self.forward(x)\n",
    "                _, _, h, w = y.shape\n",
    "                # assert (h == 64 and w == 64)\n",
    "                pixel_loss = self.test_criterion(pred_frames, y)\n",
    "                frame_loss = pixel_loss * h * w\n",
    "                total_loss += frame_loss\n",
    "            mean_loss = total_loss/len(test_loader)\n",
    "            if logger:\n",
    "                logger.log_metric(f'test_loss', mean_loss)\n",
    "        self.train()\n",
    "        if verbose:\n",
    "            print(f\"Testing loss: {mean_loss.item():.04f}\")\n",
    "        return mean_loss\n",
    "\n",
    "    def configure_optimizers(self, lr=0.001):\n",
    "        optimizer_g = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        optimizer_f = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        optimizer_y = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        return [optimizer_g, optimizer_f, optimizer_y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/peterpdai/test/e/TEST-171\n",
      "Starting a training run...\n",
      "Model will be saved at  ./exp_vid_rnn/run-starting-at-11-18-06:39:32-TEST-171  after training.\n",
      "Epoch \t\t val_loss \t\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c767da1bd254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Starting training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m my_trainer.train(model, train_loader,\n\u001b[0;32m---> 40\u001b[0;31m               logger=nep_experiment, root_dir=exp_dir)\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mmy_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/seqTP/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, train_loader, val_loader, logger, root_dir)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# Train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             batch_losses = model.train_epoch(\n\u001b[0;32m---> 77\u001b[0;31m                 train_loader, optimizers, logger, epoch, verbose=True)  # might be None\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-00bc09b6f551>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, train_loader, optimizers, logger, epoch, verbose)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;31m# print(x.max())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mtotal_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             h_ = torch.zeros(batch_sz, self.hidden_dim,\n\u001b[1;32m     76\u001b[0m                              device=self.get_device())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp_dir = './exp_vid_rnn/'\n",
    "data_dir = './data'\n",
    "\n",
    "hparams = {\n",
    "    'max_epochs': 100,\n",
    "    'in_dim': 64*64,\n",
    "    'hidden_dim': 1000,\n",
    "    'out_dim': 64*64,\n",
    "    'batch_size': 20,\n",
    "    'lr': 0.001,\n",
    "    'BCE_pos_weight': 1.\n",
    "}\n",
    "\n",
    "nep_project = neptune.init(project_qualified_name=\"peterpdai/test\")\n",
    "nep_experiment = nep_project.create_experiment(\n",
    "    name='RNN video prediction',\n",
    "    params=hparams,\n",
    "    upload_source_files=['*.py'],\n",
    "    tags=[\"vanilla-rnn\", \"video-prediction\"],\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_criterion = BCEWithLogitsLoss(torch.tensor(\n",
    "    [hparams['BCE_pos_weight']], device=device))\n",
    "test_criterion = BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = RNN(hparams['in_dim'], hparams['hidden_dim'],\n",
    "            hparams['out_dim'], train_criterion, test_criterion)\n",
    "\n",
    "\n",
    "my_trainer = trainer.Trainer(hparams, device)\n",
    "\n",
    "\n",
    "\n",
    "# Starting training\n",
    "my_trainer.train(model, train_loader,\n",
    "              logger=nep_experiment, root_dir=exp_dir)\n",
    "my_trainer.test(model, test_loader, logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch] *",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "neptune": {
   "notebookId": "272bb43b-c93e-4ab8-be7b-16c463c73684"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
